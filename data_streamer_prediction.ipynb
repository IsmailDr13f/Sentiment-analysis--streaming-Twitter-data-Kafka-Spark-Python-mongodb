{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baa7d9fc-18aa-409d-9eb4-8ee6de895bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-streaming-kafka-0-10_2.12:3.2.0,org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0 pyspark-shell'\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "606d3983-aaf4-4e6f-98fc-93d859316e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import json\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, udf,to_json, struct\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, StopWordsRemover\n",
    "import re\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0795e44-d37d-4c74-8ef1-a4f9986ceea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-U2UCHLDO:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>streaming Write</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1e6f79444d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create SparkSession\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"streaming Write\").\\\n",
    "        config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1').\\\n",
    "        getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16bd1e04-306f-4223-b38d-b50e60699241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kafka_df = spark \\\n",
    "        .readStream \\\n",
    "        .format(\"kafka\") \\\n",
    "        .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "        .option(\"subscribe\", \"tweets\") \\\n",
    "        .option(\"startingOffsets\",\"earliest\") \\\n",
    "        .load()\n",
    "\n",
    "kafka_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de8dbdc-57ec-43df-b1e8-011369191b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View schema for raw kafka_df\n",
    "kafka_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b52d8a9b-9985-4afc-9c36-0374ccca2a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse value from binay to string into kafka_json_df\n",
    "from pyspark.sql.functions import expr\n",
    "\n",
    "kafka_json_df = kafka_df.withColumn(\"value\", expr(\"cast(value as string)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42541fcc-a6c2-4883-883d-5ab5cf8e77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# Define schema for JSON data\n",
    "json_schema = StructType([\n",
    "    StructField(\"Tweet_ID\", StringType(), True),\n",
    "    StructField(\"Entity\", StringType(), True),\n",
    "    StructField(\"sentiment\", StringType(), True),\n",
    "    StructField(\"tweet_content\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a83cd099-a1ab-4163-8905-d5a5ba5cfcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the schema to payload to read the data\n",
    "from pyspark.sql.functions import from_json,col\n",
    "\n",
    "streaming_df = kafka_json_df.withColumn(\"values_json\", from_json(col(\"value\"), json_schema)).selectExpr(\"values_json.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcc320fd-169a-4f92-87cd-2691ac6de593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet_ID: string (nullable = true)\n",
      " |-- Entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- tweet_content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To the schema of the data, place a sample json file and change readStream to read\n",
    "streaming_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7dc63a-3409-4f1d-8a4c-76edb3d3f696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Clean_Func import clean_tweet_content\n",
    "# Define UDFs (User Defined Functions) for preprocessing\n",
    "clean_tweet_content_udf = udf(clean_tweet_content, StringType())\n",
    "\n",
    "# Apply preprocessing to streaming DataFrame\n",
    "preprocessed_df = streaming_df.withColumn(\"cleaned_tweet_content\", clean_tweet_content_udf(streaming_df[\"tweet_content\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8fb5cab-2ec2-4d52-863e-578d5a0fc1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet_ID: string (nullable = true)\n",
      " |-- Entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- tweet_content: string (nullable = true)\n",
      " |-- cleaned_tweet_content: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b8f5167-725b-494e-87e4-34e1938bfce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet_ID: string (nullable = true)\n",
      " |-- Entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- tweet_content: string (nullable = true)\n",
      " |-- cleaned_tweet_content: string (nullable = true)\n",
      " |-- Tweet_vect_: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- Filtered_tweet: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "# Load the model to use:\n",
    "loaded_model = PipelineModel.load('pipeline_v1')\n",
    "\n",
    "\n",
    "# Apply the pre-trained model to make predictions\n",
    "predictions_df = loaded_model.transform(preprocessed_df)\n",
    "\n",
    "# Show the predictions\n",
    "predictions_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dab2d6-ace0-4210-ad38-a6471d3da545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Tweet_ID: string (nullable = true)\n",
      " |-- Entity: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- tweet_content: string (nullable = true)\n",
      " |-- cleaned_tweet_content: string (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "alfa = predictions_df.select(\"Tweet_ID\", \"Entity\", \"sentiment\", \"tweet_content\", \"cleaned_tweet_content\", \"prediction\")\n",
    "alfa.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f46414-c527-4966-b339-2128d754d944",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = alfa \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"json\")\\\n",
    "    .option(\"path\", \"json_files\")\\\n",
    "    .option(\"checkpointLocation\", \"checkpoints\")\\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c7f12-e94f-44b2-976d-5f64c1ad353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624faba-9b4b-4b7a-82eb-b606357c2ab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
